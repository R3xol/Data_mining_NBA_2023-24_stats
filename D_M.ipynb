{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do utworzenia Stats_2024.html\n",
    "import requests # make a request to the webpage to download it\n",
    "import time\n",
    "\n",
    "url = \"https://www.basketball-reference.com/leagues/NBA_2024_totals.html\"\n",
    "\n",
    "# create a url\n",
    "data = requests.get(url)\n",
    "    \n",
    "# W+ opens file in write mode and if it already exists it will just overwrite.\n",
    "with open(\"Stats_2024.html\", \"w+\", encoding = \"utf-8\") as f:\n",
    "    time.sleep(3)\n",
    "    f.write(data.text) #text saves files as html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import beautiful soup\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# read the HTML data\n",
    "with open(\"Stats_2024.html\", encoding=\"utf-8\") as f:\n",
    "    page = f.read()\n",
    "\n",
    "# create a parser class to extract table from the page\n",
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "# remove the top row of the table\n",
    "'''soup.find(\"tr\", class_=\"over_header\").decompose()\n",
    "print(\"Header row removed successfully\")'''\n",
    "\n",
    "# find the specific table we want using its id\n",
    "mvp_table = soup.find(id=\"all_totals_stats\")\n",
    "Stats = pd.read_html(str(mvp_table))\n",
    "\n",
    "# Data Frame \n",
    "df = pd.DataFrame(Stats[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "numeric_columns = ['Rk' ,'Age', 'G' , 'GS'  ,  'MP'  , 'FG'  , 'FGA' ,  'FG%'  , '3P' , '3PA' ,  '3P%' ,  '2P' , '2PA'  , '2P%' , 'eFG%',   'FT', 'FTA' ,  'FT%',  'ORB'  ,'DRB' , 'TRB',  'AST' ,'STL' ,'BLK',  'TOV'  , 'PF',   'PTS']\n",
    "df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# usunięcie tych które mają w Rk nan (wszędzie nan)\n",
    "df = df.dropna(subset='Rk')\n",
    "\n",
    "#usunięcie powturzeń (zostają wyniki z całego sezonu)\n",
    "df = df.loc[df.groupby('Player')['G'].idxmax()]\n",
    "\n",
    "# Zastąpienie NaN przez 0\n",
    "df = df.fillna(0)\n",
    "\n",
    "string_columns = ['Player', 'Pos', 'Tm']\n",
    "# Zamiana wybranych kolumn na typ string\n",
    "df[string_columns] = df[string_columns].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Średnio punktów na mecz\n",
    "df['PPG'] = df['PTS'] / df['G']\n",
    "# Średnio minut na mecz\n",
    "df['MPG'] = df['MP'] / df['G']\n",
    "df['ORBPG'] = df['ORB'] / df['G']\n",
    "df['DRBPG'] = df['DRB'] / df['G']\n",
    "df['TRBPG'] = df['TRB'] / df['G']\n",
    "df['ASTPG'] = df['AST'] / df['G']\n",
    "df['STLPG'] = df['STL'] / df['G']\n",
    "df['BLKPG'] = df['BLK'] / df['G']\n",
    "df['TOVPG'] = df['TOV'] / df['G']\n",
    "df['PFPG'] = df['PF'] / df['G']\n",
    "\n",
    "# Utworzenie zmiennej sprawdzającej czy ktoś jest gwiazgą ;)\n",
    "df['Star'] = ((df['GS'] > ((2*df['G']) / 3)) & (df['G'] > 60)).astype(int)\n",
    "count_of_stars = df['Star'].sum()\n",
    "\n",
    "print(\"Liczba nowych zmiennych z wartością 1:\", count_of_stars)\n",
    "\n",
    "# Utworzenie zmiennej sprawdzającej czy ktoś jest aktywnie grający ;)\n",
    "df['Active'] = ((df['MPG'] > 8) & (df['G'] > 40)).astype(int)\n",
    "count_of_activ = df['Active'].sum()\n",
    "\n",
    "'''\n",
    "Bardzo ważne: Zostawiamy tylko zawodników którzy faktycznie grają\n",
    "'''\n",
    "df = df[df['Active'] == 1]\n",
    "\n",
    "# Dalej już bez RK (Numer pożądkowy)\n",
    "numeric_columns = ['Age',  'G', 'GS', 'eFG%', 'FT%', 'TRBPG', 'ASTPG', 'STLPG', 'BLKPG', 'TOVPG', 'PFPG', 'PPG', 'MPG']\n",
    "\n",
    "# Procenty *100\n",
    "percent_columns = ['FG%', '3P%','2P%', 'eFG%', 'FT%', ]\n",
    "df[percent_columns] = df[percent_columns] * 100\n",
    "\n",
    "df = df.loc[:, ['Age','Player', 'Pos', 'Tm', 'G', 'GS', 'eFG%', 'FT%', 'TRBPG', 'ASTPG', 'STLPG', 'BLKPG', 'TOVPG', 'PFPG', 'PPG', 'MPG', 'Star', 'Active']]\n",
    "\n",
    "# Eksportowanie DataFrame do pliku CSV\n",
    "df.to_csv('df.csv', index=True, index_label='Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Zakładamy, że masz DataFrame o nazwie df\n",
    "# Funkcja do usuwania wartości odstających na podstawie IQR\n",
    "def remove_outliers_iqr(df):\n",
    "    Q1 = df.quantile(0.25)\n",
    "    Q3 = df.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    mask = ~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "    return df[mask]\n",
    "\n",
    "# Usunięcie wartości odstających\n",
    "df_cleaned = remove_outliers_iqr(df.select_dtypes(include=[np.number]))\n",
    "\n",
    "# Dodanie kolumn nie numerycznych z powrotem do df_cleaned\n",
    "df = df_cleaned.join(df[df.columns.difference(df_cleaned.columns)])\n",
    "\n",
    "# Eksportowanie DataFrame do pliku CSV\n",
    "df.to_csv('df_po_wyczyszceniu_IQR.csv', index=True, index_label='Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis, shapiro, jarque_bera\n",
    "\n",
    "# Sprawdzenie Normalności rozkładu df\n",
    "\n",
    "# Zainicjalizowanie słowników do przechowywania wyników\n",
    "skewness = {}\n",
    "kurtosis_values = {}\n",
    "shapiro_p_values = {}\n",
    "jb_p_values = {}\n",
    "\n",
    "# Iteracja po każdej kolumnie DataFrame\n",
    "for column in df.select_dtypes(include=[np.number]).columns:\n",
    "    # Obliczanie skośności i kurtozy\n",
    "    skewness[column] = skew(df[column].dropna())\n",
    "    kurtosis_values[column] = kurtosis(df[column].dropna())\n",
    "    \n",
    "    # Przeprowadzenie testu Shapiro-Wilka\n",
    "    stat, p_value = shapiro(df[column].dropna())\n",
    "    shapiro_p_values[column] = p_value\n",
    "\n",
    "    # Przeprowadzenie testu Jarque-Bera\n",
    "    jb_stat, jb_p_value = jarque_bera(df[column].dropna())\n",
    "    jb_p_values[column] = jb_p_value\n",
    "\n",
    "\n",
    "# Tworzenie DataFrame z wynikami\n",
    "results = pd.DataFrame({\n",
    "    'Skośność': skewness,\n",
    "    'Kurtoza': kurtosis_values,\n",
    "    'Shapiro-Wilk p-value': shapiro_p_values,\n",
    "    'Jarque-Bera p-value': jb_p_values\n",
    "})\n",
    "\n",
    "# Wyświetlenie wyników\n",
    "print(results)\n",
    "\n",
    "# Interpretacja wyników Shapiro-Wilk\n",
    "alpha = 0.05\n",
    "results['Normalność_S-W'] = results['Shapiro-Wilk p-value'].apply(lambda p: 'Normalny' if p > alpha else 'Nie normalny')\n",
    "\n",
    "# Interpretacja wyników Jarque-Bera\n",
    "alpha = 0.05\n",
    "results['Normalność_J-B'] = results['Jarque-Bera p-value'].apply(lambda p: 'Normalny' if p > alpha else 'Nie normalny')\n",
    "\n",
    "\n",
    "# Eksportowanie DataFrame do pliku CSV\n",
    "results.to_csv('results.csv', index=True, index_label='Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = df.describe()\n",
    "\n",
    "# Eksportowanie DataFrame do pliku CSV\n",
    "description.to_csv('description.csv', index=True, index_label='Index')\n",
    "\n",
    "# tu jest numpy arr, niewiem jescze po co ale jest xD\n",
    "'''Stats_arr = df.to_numpy()\n",
    "print(type(Stats_arr))\n",
    "print(Stats_arr[0])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df.loc[0])\n",
    "\n",
    "print(\"\\nŚrednia dla wybranych kolumn:\")\n",
    "print(df[numeric_columns].mean())  # średnia\n",
    "print(\"\\nMediana dla wybranych kolumn:\")\n",
    "print(df[numeric_columns].median())  # mediana\n",
    "print(\"\\nModa dla wybranych kolumn:\")\n",
    "print(df[numeric_columns].mode())  # moda\n",
    "print(\"\\nOdchylenie standardowe dla wybranych kolumn:\")\n",
    "print(df[numeric_columns].std())  # odchylenie standardowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworzenie wykresu box plot dla każdej kolumny\n",
    "plt.figure(figsize=(12, 20))\n",
    "for i, column in enumerate(numeric_columns, 1):\n",
    "    #plt.figure(figsize=(7, 4))\n",
    "    plt.subplot(9, 3, i)  # Ustawiamy aktualny subplot w siatce 3x9\n",
    "    sns.boxplot(y=df[column])\n",
    "    plt.title(f'Box plot for {column}')\n",
    "    plt.ylabel(column)\n",
    "    #plt.show()\n",
    "\n",
    "plt.tight_layout()  # Dostosowujemy układ subplotów, aby uniknąć nachodzenia się\n",
    "plt.show()  # Wyświetlamy wykresy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Znalezienie wartości NaN w DataFrame\n",
    "nan_values = df.isna()\n",
    "print(\"Wartości NaN w DataFrame:\")\n",
    "print(nan_values)\n",
    "\n",
    "# Znalezienie wartości równych 0 w DataFrame\n",
    "zero_values = df == 0\n",
    "print(\"Wartości równe 0 w DataFrame:\")\n",
    "print(zero_values)\n",
    "\n",
    "# Wartości NaN w wybranych kolumnach\n",
    "print(\"\\nWartości NaN w wybranych kolumnach:\")\n",
    "print(df[numeric_columns].isna())\n",
    "\n",
    "# Wartości równe 0 w wybranych kolumnach\n",
    "print(\"\\nWartości równe 0 w wybranych kolumnach:\")\n",
    "print(df[numeric_columns] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyświetlenie wierszy zawierających NaN w wybranych kolumnach\n",
    "print(\"\\nWiersze zawierające NaN w wybranych kolumnach:\")\n",
    "print(df[numeric_columns][df[numeric_columns].isna().any(axis=1)])\n",
    "\n",
    "# Wyświetlenie wierszy zawierających wartości równe 0 w wybranych kolumnach\n",
    "print(\"\\nWiersze zawierające wartości równe 0 w wybranych kolumnach:\")\n",
    "print(df[numeric_columns][(df[numeric_columns] == 0).any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyznaczenie macierzy korelacji\n",
    "correlation_matrix = df[numeric_columns].corr()\n",
    "\n",
    "# Wyświetlenie macierzy korelacji\n",
    "print(\"Macierz korelacji:\")\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ustawienie rozmiaru wykresu\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Tworzenie heatmapy macierzy korelacji\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "\n",
    "# Dodanie tytułu\n",
    "plt.title('Macierz korelacji')\n",
    "\n",
    "# Wyświetlenie wykresu\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworzenie wykresu\n",
    "plt.figure(figsize=(12, 20))\n",
    "\n",
    "for i, column in enumerate(numeric_columns, 1):\n",
    "    plt.subplot(9, 3, i)  # Ustawiamy aktualny subplot w siatce 3x9\n",
    "    df[column].hist(figsize=(12, 20), bins = 10, edgecolor='black')\n",
    "    plt.title(f'Histogram for {column}')\n",
    "    plt.xlabel(column)\n",
    "    #plt.show()\n",
    "\n",
    "plt.tight_layout()  # Dostosowujemy układ subplotów, aby uniknąć nachodzenia się\n",
    "plt.show()  # Wyświetlamy wykresy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przykład: Zależność\n",
    "x_column = 'eFG%'\n",
    "y_column = 'PPG'\n",
    "\n",
    "# Stworzenie wykresu rozrzutu\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.scatter(df[x_column], df[y_column], s=5, alpha=0.5)\n",
    "plt.title(f'Zależność między {x_column} a {y_column}')\n",
    "plt.xlabel(x_column)\n",
    "plt.ylabel(y_column)\n",
    "plt.grid(False)\n",
    "\n",
    "# Wyświetlenie wykresu\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Sprawdzenie typów danych i przekształcenie kolumny \"Pos\" na kategorię\n",
    "df['Pos'] = df['Pos'].astype('category')\n",
    "\n",
    "# Wybieranie cech i etykiet\n",
    "X = df.loc[:, [ 'eFG%', '3P%','2P%','FT%',  'PPG', 'MPG', 'TRBPG',  'ASTPG' ,'STLPG' ,'BLKPG',  'TOVPG'  , 'PFPG']]\n",
    "y = df['Pos']  # Etykiety (kolumna \"Pos\")\n",
    "\n",
    "# Podział danych na zbiór treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=23)\n",
    "\n",
    "# Normalizacja danych\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Trenowanie modelu KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=10)  # liczba sąsiadów\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predykcja na zbiorze testowym\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Ocena modelu\n",
    "Confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))\n",
    "Accuracy_score = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "# Model liniowy\n",
    "\n",
    "# Wybieranie cech i etykiet\n",
    "X = df.loc[:, ['G','GS', 'eFG%', 'FT%', 'TRBPG', 'ASTPG', 'STLPG', 'BLKPG', 'PFPG']]\n",
    "y = df['PPG']\n",
    "\n",
    "# Dodanie kolumny stałej (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Zbudowanie modelu regresji liniowej\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Wyświetlenie podsumowania modelu\n",
    "print(model.summary())\n",
    "# Wyodrębnienie wartości p dla każdego współczynnika\n",
    "p_values = model.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "# Przykładowe statystyki zawodnika\n",
    "player_stats = {\n",
    "    'const': [1],\n",
    "    'G': [82],           \n",
    "    'GS': [82],          \n",
    "    'eFG%': [0.55],      \n",
    "    'FT%': [0.85],       \n",
    "    'TRBPG': [10.0],     \n",
    "    'ASTPG': [5.0],      \n",
    "    'STLPG': [1.5],      \n",
    "    'BLKPG': [3.0],      \n",
    "    'TOVPG': [2.0],      \n",
    "    'PFPG': [3.0]        \n",
    "}\n",
    "\n",
    "# Tworzenie DataFrame z przykładowymi statystykami\n",
    "player_df = pd.DataFrame(player_stats)\n",
    "\n",
    "# Dodawanie stałej kolumny do DataFrame\n",
    "player_df = sm.add_constant(player_df)\n",
    "\n",
    "# Dokonywanie predykcji\n",
    "predicted_pts = model.predict(player_df)\n",
    "\n",
    "# Wyświetlanie przewidywanej liczby punktów na mecz\n",
    "print(f\"Przewidywana liczba punktów na mecz: {predicted_pts[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)\n",
    "\n",
    "# Obliczenie reszt\n",
    "residuals = y - y_pred\n",
    "standardized_residuals = (residuals - np.mean(residuals)) / np.std(residuals)\n",
    "\n",
    "# Rysowanie rzeczywistych vs przewidywanych wartości punktów\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y, y_pred, alpha=0.5, s=10)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], color='red', lw=1)  # Linia idealna\n",
    "plt.xlabel('Rzeczywiste PTS')\n",
    "plt.ylabel('Przewidywane PTS')\n",
    "plt.title('Rzeczywiste vs Przewidywane PTS')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Wykres reszt\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_pred, residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='red', linestyle='--', linewidth=1)\n",
    "plt.xlabel('Przewidywane PTS')\n",
    "plt.ylabel('Reszty')\n",
    "plt.title('Wykres reszt')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Histogram reszt\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(residuals, kde=True, bins=30)\n",
    "plt.xlabel('Reszty')\n",
    "plt.ylabel('Częstość')\n",
    "plt.title('Histogram reszt')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Wykres standaryzowanych reszt\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_pred, standardized_residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='red', linestyle='--', linewidth=1)\n",
    "plt.xlabel('Przewidywane PTS')\n",
    "plt.ylabel('Standaryzowane Reszty')\n",
    "plt.title('Wykres Standaryzowanych Reszt')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# QQ Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sm.qqplot(standardized_residuals, line ='45')\n",
    "plt.title('QQ Plot Standaryzowanych Reszt')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "# Wyznaczanie statystyk DFFITS i DFBETAS\n",
    "influence = model.get_influence()\n",
    "dffits = influence.dffits[0]\n",
    "dfbetas = influence.dfbetas\n",
    "cook_dist = influence.cooks_distance[0]\n",
    "\n",
    "len = df.shape[0]\n",
    "\n",
    "# Identify influential observations based on Cook's distance\n",
    "df['influential_cook'] = np.where(cook_dist > 4 / len, 1, 0)\n",
    "\n",
    "# Identify influentialobservations based on DFFITS\n",
    "df['influential_dffits'] = np.where(np.abs(dffits) > 2 * np.sqrt(len * model.df_model / model.df_resid), 1, 0)\n",
    "\n",
    "'''# Identify influential observations based on DFBETAS for a specific coefficient\n",
    "coefficient_index = 0  # Index of the coefficient to analyze\n",
    "df['influential_dfbetas'] = np.where(np.abs(dfbetas[:, coefficient_index]) > 2 / np.sqrt(len), 1, 0)'''\n",
    "\n",
    "# Oblicz standaryzowane reszty\n",
    "standardized_residuals = model.get_influence().resid_studentized_internal\n",
    "\n",
    "# Dodaj standaryzowane reszty do DataFrame\n",
    "df['standardized_residuals'] = standardized_residuals\n",
    "\n",
    "# Dodaj kolumnę z wartością 1 jeśli standardized_residuals < 2, inaczej 0\n",
    "df['residuals_indicator'] = np.where(np.abs(df['standardized_residuals']) > 2, 1, 0)\n",
    "\n",
    "inf = ['residuals_indicator', 'influential_cook', 'influential_dffits']\n",
    "\n",
    "df[inf] = df[inf].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usunięcie wpływowych\n",
    "df = df[df['residuals_indicator'] == 0]\n",
    "df = df[df['influential_dffits'] == 0]\n",
    "df = df[df['influential_cook'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predykcja wartości na podstawie modelu\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Narysowanie rzeczywistych vs przewidywanych wartości punktów\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y, y_pred, alpha=0.5)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], color='red', lw=2)  # Linia idealna\n",
    "plt.xlabel('Rzeczywiste PTS')\n",
    "plt.ylabel('Przewidywane PTS')\n",
    "plt.title('Rzeczywiste vs Przewidywane PTS')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dzrewo\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Wybieranie cech i etykiet\n",
    "X = df.loc[:, ['Age', 'G', 'eFG%', 'FT%', 'TRBPG', 'ASTPG', 'STLPG', 'BLKPG', 'TOVPG', 'PFPG']]\n",
    "#X = df.drop(columns=['PTS', 'Rk','Player', 'Pos', 'Tm',  'G' , 'GS'  ,  'MP'  , 'FG'  , 'FGA' , '3P' , '3PA' ,   '2P' , '2PA' ,   'FT', 'FTA' ,  'PTS', 'PPG', 'MPG'])\n",
    "y = df['Pos']  # Etykiety (kolumna \"Pos\")\n",
    "\n",
    "# Podział danych na zbiór treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=23)\n",
    "\n",
    "# Budowanie modelu drzewa decyzyjnego\n",
    "dt_classifier = DecisionTreeClassifier(random_state=23)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predykcja na zbiorze testowym\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Ewaluacja modelu\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# Narysowanie drzewa decyzyjnego\n",
    "plt.figure(figsize=(20, 10))  # Ustawienie rozmiaru wykresu\n",
    "plot_tree(dt_classifier, filled=True, feature_names=X.columns, class_names=y.unique())\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Metody_Numeryczne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
